{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Thank you so much for sticking with this learning module until the end. You learned a lot, and now you have the basic tools to make predictions using your own data. You learned how to prepare your data, how to define your neural network, how to train and test it, and finally how to make a prediction using your trained network. \n",
        "\n",
        "In this notebook, we bring together the most important parts of the code you saw throughout this module, so you can easily refer to it in the future."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from typing import Tuple\n",
        "import requests\n",
        "from PIL import Image\n",
        "\n",
        "class NeuralNetwork(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.sequence = tf.keras.Sequential([\n",
        "      tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "      tf.keras.layers.Dense(20, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "    ])\n",
        "\n",
        "  def call(self, x: tf.Tensor) -> tf.Tensor:\n",
        "    y_prime = self.sequence(x)\n",
        "    return y_prime\n",
        "\n",
        "\n",
        "labels_map = {\n",
        "    0: 'T-Shirt',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle Boot',\n",
        "  }\n",
        "\n",
        "\n",
        "def read_images(path: str, image_size: int, num_items: int) -> np.ndarray:\n",
        "  with gzip.open(path, 'rb') as file:\n",
        "    data = np.frombuffer(file.read(), np.uint8, offset=16)\n",
        "    data = data.reshape(num_items, image_size, image_size)\n",
        "  return data\n",
        "\n",
        "\n",
        "def read_labels(path: str, num_items: int) -> np.ndarray:\n",
        "  with gzip.open(path, 'rb') as file:\n",
        "    data = np.frombuffer(file.read(num_items + 8), np.uint8, offset=8)\n",
        "    data = data.astype(np.int64)\n",
        "  return data\n",
        "\n",
        "\n",
        "def get_data(batch_size: int) -> Tuple[tf.data.Dataset, tf.data.Dataset]:\n",
        "  image_size = 28\n",
        "  num_train = 60000\n",
        "  num_test = 10000\n",
        "\n",
        "  training_images = read_images('data/FashionMNIST/raw/train-images-idx3-ubyte.gz', image_size, num_train)\n",
        "  test_images = read_images('data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz', image_size, num_test)\n",
        "  training_labels = read_labels('data/FashionMNIST/raw/train-labels-idx1-ubyte.gz', num_train)\n",
        "  test_labels = read_labels('data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz', num_test)\n",
        "\n",
        "  # (training_images, training_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((training_images, training_labels))\n",
        "  test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "\n",
        "  train_dataset = train_dataset.map(lambda image, label: (float(image) / 255.0, label))\n",
        "  test_dataset = test_dataset.map(lambda image, label: (float(image) / 255.0, label))\n",
        "\n",
        "  train_dataset = train_dataset.batch(batch_size).shuffle(500)\n",
        "  test_dataset = test_dataset.batch(batch_size).shuffle(500)\n",
        "\n",
        "  return (train_dataset, test_dataset)\n",
        "\n",
        "\n",
        "def training_phase():\n",
        "  learning_rate = 0.1\n",
        "  batch_size = 64\n",
        "  epochs = 5\n",
        "\n",
        "  (train_dataset, test_dataset) = get_data(batch_size)\n",
        "\n",
        "  model = NeuralNetwork()\n",
        "\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "  optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
        "  metrics = ['accuracy']\n",
        "  model.compile(optimizer, loss_fn, metrics)\n",
        "\n",
        "  print('\\nFitting:')\n",
        "  model.fit(train_dataset, epochs=epochs)\n",
        "    \n",
        "  print('\\nEvaluating:')\n",
        "  (test_loss, test_accuracy) = model.evaluate(test_dataset)\n",
        "  print(f'\\nTest accuracy: {test_accuracy * 100:>0.1f}%, test loss: {test_loss:>8f}')\n",
        "\n",
        "  model.save('outputs/model')\n",
        "\n",
        "\n",
        "def inference_phase():\n",
        "  print('\\nPredicting:')\n",
        "\n",
        "  model = tf.keras.models.load_model('outputs/model')\n",
        "\n",
        "  url = 'https://raw.githubusercontent.com/MicrosoftDocs/tensorflow-learning-path/main/intro-keras/predict-image.png'\n",
        "\n",
        "  with Image.open(requests.get(url, stream=True).raw) as image:\n",
        "    X = np.asarray(image, dtype=np.float32).reshape((-1, 28, 28)) / 255.0\n",
        "\n",
        "  predicted_vector = model.predict(X)\n",
        "  predicted_index = np.argmax(predicted_vector)\n",
        "  predicted_name = labels_map[predicted_index]\n",
        "\n",
        "  print(f'Predicted class: {predicted_name}')\n",
        "\n",
        "\n",
        "training_phase()\n",
        "inference_phase()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": "2025-03-17 12:04:07.649119: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n2025-03-17 12:04:07.895549: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n2025-03-17 12:04:07.895617: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vm44c605517f): /proc/driver/nvidia/version does not exist\n2025-03-17 12:04:07.934774: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n2025-03-17 12:04:08.225518: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2095170000 Hz\n2025-03-17 12:04:08.254688: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f321000ae70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n2025-03-17 12:04:08.254730: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n2025-03-17 12:04:10.633282: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 47040000 exceeds 10% of free system memory.\n2025-03-17 12:04:22.570115: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 47040000 exceeds 10% of free system memory.\n2025-03-17 12:04:37.211831: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 47040000 exceeds 10% of free system memory.\n"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Epoch 1/5\n827/938 [=========================>....] - ETA: 0s - loss: 0.4557 - accuracy: 0.8355Epoch 3/5\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n938/938 [==============================] - 5s 5ms/step - loss: 0.4180 - accuracy: 0.8506\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n938/938 [==============================] - 6s 6ms/step - loss: 0.4009 - accuracy: 0.8559\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\nEpoch 5/5\n938/938 [==============================] - 6s 6ms/step - loss: 0.3861 - accuracy: 0.8608\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\nEvaluating:\n157/157 [==============================] - 0s 3ms/step - loss: 0.4205 - accuracy: 0.8517\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n\nTest accuracy: 85.2%, test loss: 0.420531\nWARNING:tensorflow:From /anaconda/envs/azureml_py38/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\nInstructions for updating:\nIf using Keras pass *_constraint arguments to layers.\nINFO:tensorflow:Assets written to: outputs/model/assets\n\nPredicting:\nPredicted class: Ankle Boot\n"
        }
      ],
      "execution_count": 1,
      "metadata": {}
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "a7d8d32a02de2fe32a77a4e581138922e011c09664b6c2991156e76c4176efab"
    },
    "kernel_info": {
      "name": "conda-env-azureml_py38-py"
    },
    "kernelspec": {
      "name": "conda-env-azureml_py38-py",
      "language": "python",
      "display_name": "azureml_py38"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}